{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python : 3.9.21\n",
    "# Created: Jan. 03. 2025\n",
    "# Updated: Jan. 03. 2025\n",
    "# Author: D.W. SHIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.4.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.2)\n",
      "Requirement already satisfied: certifi in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/shin/miniconda3/envs/llm-finetuning/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Using cached ollama-0.4.5-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, pydantic, ollama\n",
      "Successfully installed annotated-types-0.7.0 ollama-0.4.5 pydantic-2.10.4 pydantic-core-2.27.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "    model='llama3.2-vision:11b',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['image.png']\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2-vision:11b' created_at='2025-01-06T00:53:17.526791592Z' done=True done_reason='stop' total_duration=6214838564 load_duration=4141742672 prompt_eval_count=18 prompt_eval_duration=1277000000 eval_count=53 eval_duration=642000000 message=Message(role='assistant', content='This photo depicts a green garbage truck, a white water tank and an industrial plant visible in the background. The image has been taken on a sunny day and features a clear blue sky with some clouds. There are also grassy areas in front of the vehicle.', images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2-vision:11b' created_at='2025-01-06T00:54:10.607877569Z' done=True done_reason='stop' total_duration=96962111 load_duration=10955316 prompt_eval_count=14 prompt_eval_duration=21000000 eval_count=8 eval_duration=64000000 message=Message(role='assistant', content='How can I assist you today?', images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model='llama3.2-vision:11b',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Hi, Llama'\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
