# Ollama Settings
OLLAMA_BASE_URL=http://localhost:11434  # Ollama API endpoint
# Ollama에서 사용할 LLM(질의응답) 모델명 (예: qwen3:30b-a3b)
OLLAMA_LLM_MODEL=qwen3:30b-a3b
# Ollama에서 사용할 임베딩 모델명 (예: nomic-embed-text)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text



